<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html class="gr__ai_stanford_edu"><head> 
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-93062604-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-93062604-2'); 
  </script>
</head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <style type="text/css">
    #sectiontohide {
      padding: 20px;
      background: #f0f0f0;
      width: 400px;
    }
  </style>
  <script type="text/javascript">
    function toggle_div_fun(id) {

      var divelement = document.getElementById(id);

      if (divelement.style.display == 'none')
        divelement.style.display = 'block';
      else
        divelement.style.display = 'none';
    }
  </script>
  <link rel="icon" type="image/png" href="../assets/cv/cuhk.png">
  <title>Shijia Huang</title>

<body data-gr-c-s-loaded="true">
  <table width="1050" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Shijia Huang</name>
              </p>
              <p>
                I received my PhD degree at the Department of Computer Science & Engineering from <a href="https://www.cse.cuhk.edu.hk/en/">The Chinese University of Hong Kong (CUHK)</a> in 2024. I am fortunate to work with <a href="https://lwwangcse.github.io/">Prof. Liwei Wang</a>.               
              </p>
              <p>
                Before that, I received my B.Eng. degree in School of Computer Science and Engineering from <a href="https://www.scut.edu.cn/en/">South China University of Technology (SCUT)</a> in 2020. 
              </p>
              <p>
                My research interests lie primarily in multi-modal and deep learning, particularly focusing on <b>Visual Grounding in 2D/3D Worlds, Large Language Models, and Embodied AI</b>.
              </p>
              <p align="center">
                <a href="mailto:sjhuang@cse.cuhk.edu.hk"> Email </a> /
                <a href="https://github.com/sega-hsj"> Github </a>
              </p>
            </td>
            <td width="33%">
              <img src="./pic.jpg" width="150" height="200">
            </td>
          </tr>
        </tbody></table>


<!--         <br><br>
         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
              <heading>Timeline</heading>
          </tr>
        </tbody></table>

         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <p>
            <ul>
                <li>[March 2022] Two papers got accepted by CVPR2022. </li>
                <li>[April 2020] Code for DSGN is released! </li>
                <li>[March 2020] DSGN is accepted by CVPR 2020.</li>
                <li>[June 2019] Fast Point R-CNN is accepted by ICCV 2019. </li>
                <li>[March 2018] Joined Youtu-Lab at Tencent as a research intern.</li>
                <li>[February 2018] One paper is accepted by CVPR 2018</li>
                <li>[Oct 2017] Won <b>1st Place</b> in <a href="https://places-coco2017.github.io/"> COCO 2017 Keypoint Challenge </a> </li>
                <li>[Nov 2016] Joined Megvii Face++ as a research intern.</li>
            </ul>
            </p>
          </tr>
        </tbody></table>
        </br> -->

        <br><br>
        
        
         
        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Education</heading>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
         <tbody><tr>
           <td width="25%" align="center">
             <img src="./cuhk.png" alt="cuhk" width="99" height="78">
           </td>
           <td width="75%" valign="top">
              <p>
                <strong>Aug. 2020 - Present </strong>,
                <i>
                  <b>The Chinese University of Hong Kong</b>
                </i>,</p>
              <p>Ph.D. Student, Computer Science & Engineering<br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="10">
         <tbody><tr>
           <td width="25%" align="center">
             <img src="./scut.jpg" alt="cuhk" width="78" height="78">
           </td>
           <td width="75%" valign="top">
              <p>
                <strong>Aug. 2016 - July. 2020 </strong>,
                <i>
                  <b>South China University of Technology</b>
                </i>,</p>
              <p>Bachelor Degree, Computer Science & Technology<br>
              </p>
            </td>
          </tr>
        </tbody></table>
        
  
  
        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Publications</heading>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./enav.png" alt="mvt" width="210" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Towards Learning a Generalist Model for Embodied Navigation</papertitle>
                <br>
                *Duo Zheng, *<strong>Shijia Huang</strong>, Lin Zhao, Yiwu Zhong, Liwei Wang
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024</em>
                <br>
                <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zheng_Towards_Learning_a_Generalist_Model_for_Embodied_Navigation_CVPR_2024_paper.pdf">[PDF]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./mvt.png" alt="mvt" width="210" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Multi-View Transformer for 3D Visual Grounding</papertitle>
                <br>
                <strong>Shijia Huang</strong>, Yilun Chen, Jiaya Jia, Liwei Wang
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022</em>
                <br>
                <a href="https://arxiv.org/pdf/2204.02174.pdf">[PDF]</a> <a href="https://github.com/sega-hsj/MVT-3DVG">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./AutoPM.png" alt="AutoPM" width="210" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Learning Preference Model for LLMs via Automatic Preference Data Generation</papertitle>
                <br>
                <strong>Shijia Huang</strong>, Jianqiao Zhao, Yanyang Li, Liwei Wang
                <br>
                <em>The 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2023</em>
                <br>
                <a>[PDF]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
 
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./dsgn2.png" alt="DSGN++" width="230" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>DSGN++: Exploiting Visual-Spatial Relation for Stereo-based 3D Detectors</papertitle>
                <br>
                Yilun Chen, <strong>Shijia Huang</strong>, Shu Liu, Bei Yu, Jiaya Jia
                <br>
                <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022</em> 
                <br>
                <font color="ff0000" size="2"><em>Ranked 1st place among all camera-based approaches on KITTI 3D detection leaderboard (All categories, Nov. 2021).</em></font>
                <br>
                <a href="https://arxiv.org/pdf/2204.03039.pdf">[PDF]</a> <a href="https://github.com/chenyilun95/DSGN2">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./SURE.png" alt="mvt" width="210" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>A Mutual Supervision Framework for Referring Expression Segmentation and Generation</papertitle>
                <br>
                <strong>Shijia Huang</strong>, Feng Li, Hao Zhang, Shilong Liu, Lei Zhang, Liwei Wang
                <br>
                <em>International Journal of Computer Vision (IJCV) 2025</em>
                <br>
                <a href="https://link.springer.com/content/pdf/10.1007/s11263-024-02325-y.pdf">[PDF]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./cleva.png" alt="mvt" width="210" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>CLEVA: Chinese Language Models EVAluation Platform</papertitle>
                <br>
                Yanyang Li, Jianqiao Zhao, Duo Zheng, Zi-Yuan Hu, Zhi Chen, Xiaohui Su, Yongfeng Huang, <strong>Shijia Huang</strong>, Dahua Lin, Michael R. Lyu, Liwei Wang
                <br>
                <em>The 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2023</em>
                <br>
                <a href="https://arxiv.org/pdf/2308.04813">[PDF]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./DQDETR.png" alt="mvt" width="210" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>DQ-DETR: Dual Query Detection Transformer for Phrase Extraction and Grounding</papertitle>
                <br>
                Shilong Liu, Yaoyuan Liang, Feng Li, <strong>Shijia Huang</strong>, Hao Zhang, Hang Su, Jun Zhu, Lei Zhang
                <br>
                <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2023</em>
                <br>
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25261/25033">[PDF]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./MPFORMER.png" alt="mvt" width="210" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>MP-Former: Mask-Piloted Transformer for Image Segmentation</papertitle>
                <br>
                Hao Zhang, Feng Li, Hu-Sheng Xu, <strong>Shijia Huang</strong>, Shilong Liu, L. Ni, Lei Zhang
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023</em>
                <br>
                <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_MP-Former_Mask-Piloted_Transformer_for_Image_Segmentation_CVPR_2023_paper.pdf">[PDF]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        
<!--           <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Experience</heading>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tbody><tr>
              <td width="25%" align="center">
                <img src="./exp1.png" alt="exp1" width="160" height="62">
              </td>
              <td width="75%" valign="top">
                    <strong>Mar. 2020 - Present</strong>, <i><b>exp1</b></i><br> Research Intern. <br>
              <p>
                  xxxx.
              </p>
              </td>
            </tr>
          </tbody></table> -->

        
        
         <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Selected Honors</heading>
          </tr>
        </table>

         <ul>
          <li>
            <p>Postgraduate Scholarship, CUHK, 2020 - Present</p>
          </li>
          <li>
            <p>Top 10 Outstanding Students, SCUT, 2019</p>
          </li>
          <li>
            <p>China National Scholarship, SCUT, 2017 & 2018 & 2019</p>
          </li>
          <li>
            <p>The Language and Intelligence Challenge (LIC), Semantic Video Understanding track, First Place, 2022</p>
          </li>
          <li>
            <p>The ACM-ICPC Asia-East Continent Final Contest, Gold Medal, 2019</p>
          </li>
          <li>
            <p>China Collegiate Programming Contest, Xiamen Site & Harbin Site, Gold Medal, 2019</p>
          </li>
          <li>
            <p>The ACM-ICPC Asia Regional Contest Shenyang Site, Gold Medal, 2018</p>
          </li>          
        </ul>
        
       

        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Service</heading>
          </tr>
        </table>
        
        <ul>
<!--           <li>
            <p>Conference Reviewer: </p>
          </li> -->
          <li>
            <p>Reviewer: ECCV, IJCV</p>
          </li>
          <li>
            <p>Teaching: CSCI3320, CSCI1510, ENGG1100</p>
          </li>
        </ul>

        <br>
        <!-- Footer ================================================== -->
        <hr>
  
      </td>
    </tr>
  </tbody></table>


<div class="jvectormap-tip"></div></body></html>
